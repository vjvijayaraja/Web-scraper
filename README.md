# Homework helper (Web scraper)
A homework aid that extracts and organizes information from a specified document containing embedded links.

## Table of Contents
* [General Info](#general-information)
* [Features](#features)
* [Setup](#setup)
* [Usage](#usage)
* [Credits](#credits)


## General Information
This project offers a solution for efficiently extracting data from hyperlinks within a document, whether they lead to websites or PDFs. Rather than manually visiting each link to gather information, this tool automates the process by scraping data directly from the provided hyperlinks.



## Features
* Automated Data Extraction: Extracts data from hyperlinked websites and PDFs without manual intervention.
* Efficient: Saves time by eliminating the need to visit each link individually.
* Versatile: Works with a variety of hyperlink types, including both web URLs and PDF links.
* Customizable: Offers options for customizing the scraping process to suit different requirements.
* User-Friendly: Simple to use, making data extraction from hyperlinks a seamless task.




## Setup:

1. **Install Python:**
   - If you haven't already, install Python on your local machine. You can download it from the [Python official website](https://www.python.org/).

2. **Install Required Modules:**
   - Open a terminal or command prompt.
   - Run the following commands to install the necessary modules using pip:

   ```bash
   pip install python-docx
   pip install beautifulsoup4
   pip install python-pptx
   pip install requests
   pip install PyPDF2




## Usage

To use this homework helper tool, follow these steps:

1. **Clone the Repository:**
   - Clone this repository to your local machine using Git:
     ```bash
     git clone https://github.com/vjvijayaraja/Web-scraper.git
     ```
2. **Run the Application:**
   - Start the notepad application by running the following command:
     ```bash
     python challenge.py
     ```

3. **Download the Document:**
   - Obtain the document that contains the hyperlinks from which you wish to extract data.

4. **Document Naming:**
   - Make sure the document is named "Links to scrape.docx" for seamless processing.

5. **Import the Document:**
   - Clone the repository to your local machine.
   - Place the "Links to scrape.docx" document in the designated directory.

6. **Launch the Tool:**
   - Follow the provided instructions in the repository to start the tool.

7. **Initiate Data Extraction:**
   - Enter the necessary prompts as guided to start the data extraction process.

8. **Save Extracted Data:**
   - Upon completion of the scraping process, the tool will prompt you to save the extracted data.

9. **Save Data for Further Use:**
   - Save the extracted data into a text file for future analysis or any required purposes.

## Additional Notes:
* Ensure that any dependencies required by the tool are installed on your system.
* Follow the on-screen instructions to navigate through the scraping process efficiently.


## Credits
Created by Vijay Shrivarshan Vijayaraja  

